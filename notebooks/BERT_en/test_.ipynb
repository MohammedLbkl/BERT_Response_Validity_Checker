{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2b6f4df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Simoh\\BERT\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to load the English model and tokenizer from disk.\n",
      "Using device for loading: cpu\n",
      "Loading English tokenizer from: save_model_en/bert-base-uncased_coherence_tokenizer/\n",
      "Loading English model architecture: bert-base-uncased\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading saved model weights from: save_model_en/bert-base-uncased_coherence_final_model.bin\n",
      "English model and tokenizer loaded successfully from disk and ready for inference.\n"
     ]
    }
   ],
   "source": [
    "# CELL TO TEST THE MODEL WITH EXAMPLES\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import re # Ensure re is imported\n",
    "\n",
    "# --- Global Configuration for Testing (used when loading from disk) ---\n",
    "# These values MUST match those used during saving/training of the ENGLISH model\n",
    "# ***** USER: PLEASE UPDATE THESE PATHS AND MODEL NAME *****\n",
    "MODEL_NAME_FOR_ENGLISH_TEST = \"bert-base-uncased\"  # Or whatever English model you used (e.g., \"roberta-base\")\n",
    "MAX_LEN_FOR_ENGLISH_TEST = 160              # Must be the same MAX_LEN as for training\n",
    "# Construct paths based on the model name for consistency with the saving cell\n",
    "_safe_model_name_for_path_en_test = MODEL_NAME_FOR_ENGLISH_TEST.replace('/', '_')\n",
    "MODEL_PATH_FOR_ENGLISH_LOAD = f\"save_model_en/{_safe_model_name_for_path_en_test}_coherence_final_model.bin\"\n",
    "TOKENIZER_PATH_FOR_ENGLISH_LOAD = f\"save_model_en/{_safe_model_name_for_path_en_test}_coherence_tokenizer/\"\n",
    "DEVICE_FOR_ENGLISH_TEST = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# --- Text cleaning function for English prediction ---\n",
    "def clean_text_for_english_prediction(text):\n",
    "    text = str(text)\n",
    "    text = re.sub(r'<.*?>', '', text) # Remove HTML tags\n",
    "    # Keep alphanumeric, spaces, and basic punctuation relevant for English\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s\\.\\?,!\\']', '', text)\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\s+', ' ', text).strip() # Remove extra whitespace\n",
    "    return text\n",
    "\n",
    "# --- Initialize variables for testing ---\n",
    "# These will be populated by loading from disk.\n",
    "loaded_english_model = None\n",
    "loaded_english_tokenizer = None\n",
    "\n",
    "print(\"Attempting to load the English model and tokenizer from disk.\")\n",
    "print(f\"Using device for loading: {DEVICE_FOR_ENGLISH_TEST}\")\n",
    "\n",
    "try:\n",
    "    print(f\"Loading English tokenizer from: {TOKENIZER_PATH_FOR_ENGLISH_LOAD}\")\n",
    "    loaded_english_tokenizer = AutoTokenizer.from_pretrained(TOKENIZER_PATH_FOR_ENGLISH_LOAD)\n",
    "\n",
    "    print(f\"Loading English model architecture: {MODEL_NAME_FOR_ENGLISH_TEST}\")\n",
    "    # Load the model architecture first\n",
    "    loaded_english_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        MODEL_NAME_FOR_ENGLISH_TEST,\n",
    "        num_labels=2 # Should match the number of labels used during training (e.g., 2 for coherent/not coherent)\n",
    "    )\n",
    "    print(f\"Loading saved model weights from: {MODEL_PATH_FOR_ENGLISH_LOAD}\")\n",
    "    # Load the saved weights\n",
    "    loaded_english_model.load_state_dict(\n",
    "        torch.load(MODEL_PATH_FOR_ENGLISH_LOAD, map_location=DEVICE_FOR_ENGLISH_TEST)\n",
    "    )\n",
    "    loaded_english_model.to(DEVICE_FOR_ENGLISH_TEST)\n",
    "    loaded_english_model.eval() # VERY IMPORTANT: Set model to evaluation mode\n",
    "\n",
    "    print(\"English model and tokenizer loaded successfully from disk and ready for inference.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error loading model or tokenizer: {e}\")\n",
    "    print(\"Please ensure MODEL_NAME_FOR_ENGLISH_TEST, MODEL_PATH_FOR_ENGLISH_LOAD, and TOKENIZER_PATH_FOR_ENGLISH_LOAD are correct.\")\n",
    "    print(\"And that the model and tokenizer were saved correctly in the specified paths.\")\n",
    "    loaded_english_model = None # Ensure it's None if loading failed\n",
    "    loaded_english_tokenizer = None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49e68fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Adapted Prediction Function (for English BERT-like models) ---\n",
    "def predict_coherence(question, answer, model, tokenizer, device, max_len, clean_fn):\n",
    "    \"\"\"\n",
    "    Predicts the coherence between a question and an answer using the provided model.\n",
    "\n",
    "    Args:\n",
    "        question (str): The input question.\n",
    "        answer (str): The input answer.\n",
    "        model: The loaded Hugging Face model for sequence classification.\n",
    "        tokenizer: The loaded Hugging Face tokenizer.\n",
    "        device: The torch device (e.g., 'cuda' or 'cpu').\n",
    "        max_len (int): The maximum sequence length for tokenization.\n",
    "        clean_fn (function): The text cleaning function to apply.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (predicted_class_index, probability_score)\n",
    "               predicted_class_index (int): 0 for not coherent, 1 for coherent.\n",
    "               probability_score (float): The confidence score for the predicted class.\n",
    "    \"\"\"\n",
    "    if model is None or tokenizer is None:\n",
    "        print(\"Model or tokenizer not available for prediction.\")\n",
    "        return None, None\n",
    "\n",
    "    cleaned_question = clean_fn(question)\n",
    "    cleaned_answer = clean_fn(answer)\n",
    "\n",
    "    encoding = tokenizer.encode_plus(\n",
    "        cleaned_question,\n",
    "        cleaned_answer,\n",
    "        add_special_tokens=True,\n",
    "        max_length=max_len,\n",
    "        return_token_type_ids=True,  # MODIFIED: Set to True for BERT-like models\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_attention_mask=True,\n",
    "        return_tensors='pt',\n",
    "    )\n",
    "\n",
    "    input_ids = encoding['input_ids'].to(device)\n",
    "    attention_mask = encoding['attention_mask'].to(device)\n",
    "    # MODIFIED: Get token_type_ids if the tokenizer provides them\n",
    "    token_type_ids = encoding.get('token_type_ids')\n",
    "    if token_type_ids is not None:\n",
    "        token_type_ids = token_type_ids.to(device)\n",
    "\n",
    "\n",
    "    with torch.no_grad(): # Important for inference\n",
    "        # MODIFIED: Pass token_type_ids to the model if they exist\n",
    "        model_inputs = {\n",
    "            'input_ids': input_ids,\n",
    "            'attention_mask': attention_mask\n",
    "        }\n",
    "        if token_type_ids is not None:\n",
    "            model_inputs['token_type_ids'] = token_type_ids\n",
    "\n",
    "        outputs = model(**model_inputs)\n",
    "\n",
    "        logits = outputs.logits\n",
    "        probs = torch.softmax(logits, dim=1)\n",
    "        # Get the predicted class index and its probability\n",
    "        confidence_scores_for_all_classes, predicted_indices = torch.max(probs, dim=1)\n",
    "\n",
    "        prediction_idx = predicted_indices.cpu().item()\n",
    "        probability_score = confidence_scores_for_all_classes.cpu().item()\n",
    "\n",
    "    return prediction_idx, probability_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "049f5f6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Testing with specific English examples ---\n",
      "\n",
      "Example 1:\n",
      "  Question: \"Where can I find the milk?\"\n",
      "  Answer:   \"It's next to the cheese in the dairy section.\"\n",
      "  Prediction: Coherent (Label: 1, Confidence: 0.9662)\n",
      "\n",
      "Example 2:\n",
      "  Question: \"Do you have gluten-free pasta?\"\n",
      "  Answer:   \"Yes, of course, it's in the special diet aisle, next to the organic products.\"\n",
      "  Prediction: Coherent (Label: 1, Confidence: 0.9650)\n",
      "\n",
      "Example 3:\n",
      "  Question: \"I'm looking for ground coffee.\"\n",
      "  Answer:   \"The sky is blue and the birds are singing.\"\n",
      "  Prediction: Not Coherent (Label: 0, Confidence: 0.9527)\n",
      "\n",
      "Example 4:\n",
      "  Question: \"Where are the canned tomatoes?\"\n",
      "  Answer:   \"Have you thought about checking the weather forecast?\"\n",
      "  Prediction: Not Coherent (Label: 0, Confidence: 0.8576)\n",
      "\n",
      "Example 5:\n",
      "  Question: \"What is the price of apples?\"\n",
      "  Answer:   \"They are $2.50 per pound this week.\"\n",
      "  Prediction: Coherent (Label: 1, Confidence: 0.9400)\n",
      "\n",
      "Example 6:\n",
      "  Question: \"Do you have whole wheat bread?\"\n",
      "  Answer:   \"No, sorry, we are out of whole wheat bread today.\"\n",
      "  Prediction: Coherent (Label: 1, Confidence: 0.9626)\n",
      "\n",
      "Example 7:\n",
      "  Question: \"I'd like some AA batteries.\"\n",
      "  Answer:   \"Batteries are usually found near the checkouts or in the electronics aisle.\"\n",
      "  Prediction: Coherent (Label: 1, Confidence: 0.9278)\n",
      "\n",
      "Example 8:\n",
      "  Question: \"What time does the store close?\"\n",
      "  Answer:   \"We close at 9 PM tonight.\"\n",
      "  Prediction: Coherent (Label: 1, Confidence: 0.9526)\n",
      "\n",
      "Example 9:\n",
      "  Question: \"Can you recommend a good red wine?\"\n",
      "  Answer:   \"I had toast for breakfast.\"\n",
      "  Prediction: Not Coherent (Label: 0, Confidence: 0.9395)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if loaded_english_model and loaded_english_tokenizer: # Ensure the English model and tokenizer are available\n",
    "    english_test_samples = [\n",
    "        {\"question\": \"Where can I find the milk?\", \"answer\": \"It's next to the cheese in the dairy section.\"},\n",
    "        {\"question\": \"Do you have gluten-free pasta?\", \"answer\": \"Yes, of course, it's in the special diet aisle, next to the organic products.\"},\n",
    "        {\"question\": \"I'm looking for ground coffee.\", \"answer\": \"The sky is blue and the birds are singing.\"}, # Incoherent\n",
    "        {\"question\": \"Where are the canned tomatoes?\", \"answer\": \"Have you thought about checking the weather forecast?\"}, # Incoherent\n",
    "        {\"question\": \"What is the price of apples?\", \"answer\": \"They are $2.50 per pound this week.\"},\n",
    "        {\"question\": \"Do you have whole wheat bread?\", \"answer\": \"No, sorry, we are out of whole wheat bread today.\"},\n",
    "        {\"question\": \"I'd like some AA batteries.\", \"answer\": \"Batteries are usually found near the checkouts or in the electronics aisle.\"},\n",
    "        {\"question\": \"What time does the store close?\", \"answer\": \"We close at 9 PM tonight.\"},\n",
    "        {\"question\": \"Can you recommend a good red wine?\", \"answer\": \"I had toast for breakfast.\"}, # Incoherent\n",
    "    ]\n",
    "\n",
    "    print(\"\\n--- Testing with specific English examples ---\")\n",
    "    for i, sample in enumerate(english_test_samples):\n",
    "        q = sample[\"question\"]\n",
    "        a = sample[\"answer\"]\n",
    "\n",
    "        print(f\"\\nExample {i+1}:\")\n",
    "        print(f\"  Question: \\\"{q}\\\"\")\n",
    "        print(f\"  Answer:   \\\"{a}\\\"\")\n",
    "\n",
    "        # Call the adapted predict_coherence function\n",
    "        # Ensure all arguments are for the English setup\n",
    "        pred_label, pred_prob = predict_coherence(\n",
    "            question=q,\n",
    "            answer=a,\n",
    "            model=loaded_english_model,              # Your loaded English model\n",
    "            tokenizer=loaded_english_tokenizer,      # Your loaded English tokenizer\n",
    "            device=DEVICE_FOR_ENGLISH_TEST,          # Device for English model\n",
    "            max_len=MAX_LEN_FOR_ENGLISH_TEST,        # Max length for English model\n",
    "            clean_fn=clean_text_for_english_prediction # English cleaning function\n",
    "        )\n",
    "\n",
    "        if pred_label is not None: # Check if prediction was successful\n",
    "            coherence_status = \"Coherent\" if pred_label == 1 else \"Not Coherent\"\n",
    "            print(f\"  Prediction: {coherence_status} (Label: {pred_label}, Confidence: {pred_prob:.4f})\")\n",
    "        else:\n",
    "            print(\"  Prediction failed (model/tokenizer might not be loaded correctly).\")\n",
    "else:\n",
    "    print(\"\\nEnglish model or tokenizer not loaded. Cannot run test examples.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33bdf5dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
