{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e1d4c36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, get_linear_schedule_with_warmup\n",
    "from torch.optim import AdamW\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import spacy\n",
    "import seaborn as sns\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "import numpy as np \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7a7306c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 0. Charger le modèle spaCy pour le français ---\n",
    "\n",
    "nlp_fr = spacy.load('fr_core_news_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8b92bdf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aperçu initial des données:\n",
      "                                            question  \\\n",
      "0               Quelle est votre taille habituelle ?   \n",
      "1  Souhaitez-vous essayer autre chose ou passer e...   \n",
      "2               Quelle est votre taille habituelle ?   \n",
      "3               Quelle est votre taille habituelle ?   \n",
      "4  Bonjour, que puis-je faire pour vous aujourd'h...   \n",
      "\n",
      "                                              answer  label  \n",
      "0              La taille de ce mensonge est énorme !      0  \n",
      "1  Un style intemporel, que je pourrai garder lon...      0  \n",
      "2                        En caisse, s'il vous plaît.      0  \n",
      "3  Oui, je cherche quelque chose en jean, un styl...      0  \n",
      "4              Un style ethnique chic, si vous avez.      0  \n",
      "\n",
      "Dimensions du DataFrame: (3099, 3)\n",
      "\n",
      "Distribution des labels:\n",
      "label\n",
      "0    0.83414\n",
      "1    0.16586\n",
      "Name: proportion, dtype: float64\n",
      "                                    cleaned_question  \\\n",
      "0               quelle est votre taille habituelle ?   \n",
      "1  souhaitezvous essayer autre chose ou passer en...   \n",
      "2               quelle est votre taille habituelle ?   \n",
      "3               quelle est votre taille habituelle ?   \n",
      "4  bonjour, que puisje faire pour vous aujourd'hui ?   \n",
      "\n",
      "                                      cleaned_answer  label  \n",
      "0              la taille de ce mensonge est énorme !      0  \n",
      "1  un style intemporel, que je pourrai garder lon...      0  \n",
      "2                        en caisse, s'il vous plaît.      0  \n",
      "3  oui, je cherche quelque chose en jean, un styl...      0  \n",
      "4              un style ethnique chic, si vous avez.      0  \n"
     ]
    }
   ],
   "source": [
    "# --- 1. Charger et Préparer les Données ---\n",
    "\n",
    "df = pd.read_csv('../../data/data_vrsmall_fr.csv')\n",
    "\n",
    "print(\"Aperçu initial des données:\")\n",
    "print(df.head())\n",
    "print(f\"\\nDimensions du DataFrame: {df.shape}\")\n",
    "print(f\"\\nDistribution des labels:\\n{df['label'].value_counts(normalize=True)}\")\n",
    "\n",
    "def clean_text(text):\n",
    "    text = str(text)\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s\\.\\?,!àâéèêëîïôûùüçÀÂÉÈÊËÎÏÔÛÙÜÇ\\']', '', text)\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "df['cleaned_question'] = df['question'].apply(clean_text)\n",
    "df['cleaned_answer'] = df['answer'].apply(clean_text)\n",
    "\n",
    "\n",
    "print(df[['cleaned_question', 'cleaned_answer', 'label']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1edbdb2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Simoh\\Github\\BERT_Response_Validity_Checker\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comptes des classes dans l'ensemble d'entraînement : [2068  411]\n",
      "Poids inverses des fréquences des classes : [0.00048356 0.00243309]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- 2. Préparer les Données pour CamemBERT ---\n",
    "MODEL_NAME = \"camembert-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "class QACoherenceDataset(Dataset):\n",
    "    def __init__(self, questions, answers, labels, tokenizer, max_len):\n",
    "        self.questions = questions\n",
    "        self.answers = answers\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.questions)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        question = str(self.questions[item])\n",
    "        answer = str(self.answers[item])\n",
    "        label = self.labels[item]\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            question,\n",
    "            answer,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            return_token_type_ids=False,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'label': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "X_questions_train, X_questions_test, \\\n",
    "X_answers_train, X_answers_test, \\\n",
    "y_train, y_test = train_test_split(\n",
    "    df['cleaned_question'],\n",
    "    df['cleaned_answer'],\n",
    "    df['label'],\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=df['label']\n",
    ")\n",
    "\n",
    "MAX_LEN = 160\n",
    "train_dataset = QACoherenceDataset(\n",
    "    questions=X_questions_train.values,\n",
    "    answers=X_answers_train.values,\n",
    "    labels=y_train.values, \n",
    "    tokenizer=tokenizer,\n",
    "    max_len=MAX_LEN\n",
    ")\n",
    "test_dataset = QACoherenceDataset(\n",
    "    questions=X_questions_test.values,\n",
    "    answers=X_answers_test.values,\n",
    "    labels=y_test.values, \n",
    "    tokenizer=tokenizer,\n",
    "    max_len=MAX_LEN\n",
    ")\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "if isinstance(y_train, pd.Series):\n",
    "    y_train_numpy = y_train.values\n",
    "else:\n",
    "    y_train_numpy = y_train # Si c'est déjà un array numpy\n",
    "\n",
    "class_counts = np.bincount(y_train_numpy)\n",
    "print(f\"Comptes des classes dans l'ensemble d'entraînement : {class_counts}\")\n",
    "\n",
    "\n",
    "class_weights_sample = 1. / class_counts\n",
    "print(f\"Poids inverses des fréquences des classes : {class_weights_sample}\")\n",
    "\n",
    "sample_weights = np.array([class_weights_sample[label] for label in y_train_numpy])\n",
    "sample_weights_tensor = torch.from_numpy(sample_weights).double()\n",
    "\n",
    "sampler = WeightedRandomSampler(\n",
    "    weights=sample_weights_tensor,\n",
    "    num_samples=len(sample_weights_tensor),\n",
    "    replacement=True\n",
    ")\n",
    "\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    sampler=sampler, \n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False \n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1d9334d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Utilisation du device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Simoh\\Github\\BERT_Response_Validity_Checker\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of CamembertForSequenceClassification were not initialized from the model checkpoint at camembert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- 3. Définir le Modèle, l'Optimiseur, le Scheduler ---\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"\\nUtilisation du device: {device}\")\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=2)\n",
    "model = model.to(device)\n",
    "\n",
    "LEARNING_RATE = 2e-5\n",
    "ADAM_EPSILON = 1e-8\n",
    "EPOCHS = 4\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=LEARNING_RATE, eps=ADAM_EPSILON)\n",
    "total_steps = len(train_loader) * EPOCHS\n",
    "num_warmup_steps = int(0.1 * total_steps)\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=num_warmup_steps,\n",
    "    num_training_steps=total_steps\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e0deb5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. Fonctions d'Entraînement et d'Évaluation ---\n",
    "\n",
    "def train_epoch_fn(model, data_loader, optimizer, scheduler, device, n_examples):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct_predictions = 0\n",
    "    for batch_idx, batch in enumerate(data_loader):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            labels=labels\n",
    "        )\n",
    "        loss = outputs.loss\n",
    "        logits = outputs.logits\n",
    "        _, preds = torch.max(logits, dim=1)\n",
    "        correct_predictions += torch.sum(preds == labels)\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "    return correct_predictions.double() / n_examples, total_loss / len(data_loader)\n",
    "\n",
    "def eval_model_fn(model, data_loader, device, n_examples):\n",
    "    model.eval()\n",
    "    total_eval_loss = 0\n",
    "    correct_predictions = 0\n",
    "    all_true_labels = []\n",
    "    all_pred_labels = []\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                labels=labels\n",
    "            )\n",
    "            loss = outputs.loss\n",
    "            logits = outputs.logits\n",
    "            _, preds = torch.max(logits, dim=1)\n",
    "            correct_predictions += torch.sum(preds == labels)\n",
    "            total_eval_loss += loss.item()\n",
    "            all_true_labels.extend(labels.cpu().numpy())\n",
    "            all_pred_labels.extend(preds.cpu().numpy())\n",
    "    avg_loss = total_eval_loss / len(data_loader)\n",
    "    accuracy = correct_predictions.double() / n_examples\n",
    "    return accuracy, avg_loss, all_true_labels, all_pred_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3201388b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Epoch 1/4 ---\n",
      "  Train loss: 0.6384 | Train Accuracy: 0.6228\n",
      "  Val. loss: 0.4414 | Val. Accuracy: 0.8306 | Val. F1 (Classe 1): 0.6367\n",
      "  Nouveau meilleur modèle (F1 Classe 1) sauvegardé avec Val F1: 0.6367\n",
      "--- Epoch 2/4 ---\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[59]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(EPOCHS):\n\u001b[32m      8\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m--- Epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m+\u001b[38;5;250m \u001b[39m\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mEPOCHS\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m ---\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m     train_acc, train_loss = \u001b[43mtrain_epoch_fn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m     history[\u001b[33m'\u001b[39m\u001b[33mtrain_loss\u001b[39m\u001b[33m'\u001b[39m].append(train_loss)\n\u001b[32m     13\u001b[39m     history[\u001b[33m'\u001b[39m\u001b[33mtrain_acc\u001b[39m\u001b[33m'\u001b[39m].append(train_acc.item())\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[58]\u001b[39m\u001b[32m, line 12\u001b[39m, in \u001b[36mtrain_epoch_fn\u001b[39m\u001b[34m(model, data_loader, optimizer, scheduler, device, n_examples)\u001b[39m\n\u001b[32m     10\u001b[39m labels = batch[\u001b[33m'\u001b[39m\u001b[33mlabel\u001b[39m\u001b[33m'\u001b[39m].to(device)\n\u001b[32m     11\u001b[39m optimizer.zero_grad()\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m outputs = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlabels\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     17\u001b[39m loss = outputs.loss\n\u001b[32m     18\u001b[39m logits = outputs.logits\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Simoh\\Github\\BERT_Response_Validity_Checker\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Simoh\\Github\\BERT_Response_Validity_Checker\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Simoh\\Github\\BERT_Response_Validity_Checker\\.venv\\Lib\\site-packages\\transformers\\models\\camembert\\modeling_camembert.py:1060\u001b[39m, in \u001b[36mCamembertForSequenceClassification.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[39m\n\u001b[32m   1052\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1053\u001b[39m \u001b[33;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[32m   1054\u001b[39m \u001b[33;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[32m   1055\u001b[39m \u001b[33;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[32m   1056\u001b[39m \u001b[33;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[32m   1057\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1058\u001b[39m return_dict = return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config.use_return_dict\n\u001b[32m-> \u001b[39m\u001b[32m1060\u001b[39m outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mroberta\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1061\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1062\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1063\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1064\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1065\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1066\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1067\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1068\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1069\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1070\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1071\u001b[39m sequence_output = outputs[\u001b[32m0\u001b[39m]\n\u001b[32m   1072\u001b[39m logits = \u001b[38;5;28mself\u001b[39m.classifier(sequence_output)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Simoh\\Github\\BERT_Response_Validity_Checker\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Simoh\\Github\\BERT_Response_Validity_Checker\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Simoh\\Github\\BERT_Response_Validity_Checker\\.venv\\Lib\\site-packages\\transformers\\models\\camembert\\modeling_camembert.py:885\u001b[39m, in \u001b[36mCamembertModel.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[39m\n\u001b[32m    876\u001b[39m head_mask = \u001b[38;5;28mself\u001b[39m.get_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m.config.num_hidden_layers)\n\u001b[32m    878\u001b[39m embedding_output = \u001b[38;5;28mself\u001b[39m.embeddings(\n\u001b[32m    879\u001b[39m     input_ids=input_ids,\n\u001b[32m    880\u001b[39m     position_ids=position_ids,\n\u001b[32m   (...)\u001b[39m\u001b[32m    883\u001b[39m     past_key_values_length=past_key_values_length,\n\u001b[32m    884\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m885\u001b[39m encoder_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    886\u001b[39m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    887\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    889\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    890\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    891\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    892\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    893\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    894\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    895\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    896\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    897\u001b[39m sequence_output = encoder_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m    898\u001b[39m pooled_output = \u001b[38;5;28mself\u001b[39m.pooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.pooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Simoh\\Github\\BERT_Response_Validity_Checker\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Simoh\\Github\\BERT_Response_Validity_Checker\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Simoh\\Github\\BERT_Response_Validity_Checker\\.venv\\Lib\\site-packages\\transformers\\models\\camembert\\modeling_camembert.py:535\u001b[39m, in \u001b[36mCamembertEncoder.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[39m\n\u001b[32m    524\u001b[39m     layer_outputs = \u001b[38;5;28mself\u001b[39m._gradient_checkpointing_func(\n\u001b[32m    525\u001b[39m         layer_module.\u001b[34m__call__\u001b[39m,\n\u001b[32m    526\u001b[39m         hidden_states,\n\u001b[32m   (...)\u001b[39m\u001b[32m    532\u001b[39m         output_attentions,\n\u001b[32m    533\u001b[39m     )\n\u001b[32m    534\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m535\u001b[39m     layer_outputs = \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    536\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    537\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    538\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    539\u001b[39m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    540\u001b[39m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    541\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    542\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    543\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    545\u001b[39m hidden_states = layer_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m    546\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Simoh\\Github\\BERT_Response_Validity_Checker\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Simoh\\Github\\BERT_Response_Validity_Checker\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Simoh\\Github\\BERT_Response_Validity_Checker\\.venv\\Lib\\site-packages\\transformers\\models\\camembert\\modeling_camembert.py:466\u001b[39m, in \u001b[36mCamembertLayer.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[39m\n\u001b[32m    463\u001b[39m     cross_attn_present_key_value = cross_attention_outputs[-\u001b[32m1\u001b[39m]\n\u001b[32m    464\u001b[39m     present_key_value = present_key_value + cross_attn_present_key_value\n\u001b[32m--> \u001b[39m\u001b[32m466\u001b[39m layer_output = \u001b[43mapply_chunking_to_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    467\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfeed_forward_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mchunk_size_feed_forward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mseq_len_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_output\u001b[49m\n\u001b[32m    468\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    469\u001b[39m outputs = (layer_output,) + outputs\n\u001b[32m    471\u001b[39m \u001b[38;5;66;03m# if decoder, return the attn key/values as the last output\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Simoh\\Github\\BERT_Response_Validity_Checker\\.venv\\Lib\\site-packages\\transformers\\pytorch_utils.py:237\u001b[39m, in \u001b[36mapply_chunking_to_forward\u001b[39m\u001b[34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[39m\n\u001b[32m    234\u001b[39m     \u001b[38;5;66;03m# concatenate output at same dimension\u001b[39;00m\n\u001b[32m    235\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m torch.cat(output_chunks, dim=chunk_dim)\n\u001b[32m--> \u001b[39m\u001b[32m237\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43minput_tensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Simoh\\Github\\BERT_Response_Validity_Checker\\.venv\\Lib\\site-packages\\transformers\\models\\camembert\\modeling_camembert.py:479\u001b[39m, in \u001b[36mCamembertLayer.feed_forward_chunk\u001b[39m\u001b[34m(self, attention_output)\u001b[39m\n\u001b[32m    477\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfeed_forward_chunk\u001b[39m(\u001b[38;5;28mself\u001b[39m, attention_output):\n\u001b[32m    478\u001b[39m     intermediate_output = \u001b[38;5;28mself\u001b[39m.intermediate(attention_output)\n\u001b[32m--> \u001b[39m\u001b[32m479\u001b[39m     layer_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43mintermediate_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    480\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m layer_output\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Simoh\\Github\\BERT_Response_Validity_Checker\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Simoh\\Github\\BERT_Response_Validity_Checker\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Simoh\\Github\\BERT_Response_Validity_Checker\\.venv\\Lib\\site-packages\\transformers\\models\\camembert\\modeling_camembert.py:391\u001b[39m, in \u001b[36mCamembertOutput.forward\u001b[39m\u001b[34m(self, hidden_states, input_tensor)\u001b[39m\n\u001b[32m    389\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states: torch.Tensor, input_tensor: torch.Tensor) -> torch.Tensor:\n\u001b[32m    390\u001b[39m     hidden_states = \u001b[38;5;28mself\u001b[39m.dense(hidden_states)\n\u001b[32m--> \u001b[39m\u001b[32m391\u001b[39m     hidden_states = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    392\u001b[39m     hidden_states = \u001b[38;5;28mself\u001b[39m.LayerNorm(hidden_states + input_tensor)\n\u001b[32m    393\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Simoh\\Github\\BERT_Response_Validity_Checker\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Simoh\\Github\\BERT_Response_Validity_Checker\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Simoh\\Github\\BERT_Response_Validity_Checker\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\dropout.py:70\u001b[39m, in \u001b[36mDropout.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m     69\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m---> \u001b[39m\u001b[32m70\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Simoh\\Github\\BERT_Response_Validity_Checker\\.venv\\Lib\\site-packages\\torch\\nn\\functional.py:1425\u001b[39m, in \u001b[36mdropout\u001b[39m\u001b[34m(input, p, training, inplace)\u001b[39m\n\u001b[32m   1422\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m p < \u001b[32m0.0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m p > \u001b[32m1.0\u001b[39m:\n\u001b[32m   1423\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mdropout probability has to be between 0 and 1, but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mp\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m   1424\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[32m-> \u001b[39m\u001b[32m1425\u001b[39m     _VF.dropout_(\u001b[38;5;28minput\u001b[39m, p, training) \u001b[38;5;28;01mif\u001b[39;00m inplace \u001b[38;5;28;01melse\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1426\u001b[39m )\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# --- 5. Boucle d'Entraînement ---\n",
    "\n",
    "best_val_accuracy = 0\n",
    "best_val_f1_minority = 0 \n",
    "history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': [], 'val_f1_minority': []}\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f'--- Epoch {epoch + 1}/{EPOCHS} ---')\n",
    "    train_acc, train_loss = train_epoch_fn(\n",
    "        model, train_loader, optimizer, scheduler, device, len(train_dataset)\n",
    "    )\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_acc'].append(train_acc.item())\n",
    "    print(f'  Train loss: {train_loss:.4f} | Train Accuracy: {train_acc:.4f}')\n",
    "\n",
    "    val_acc, val_loss, val_true, val_pred = eval_model_fn(\n",
    "        model, test_loader, device, len(test_dataset)\n",
    "    )\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_acc'].append(val_acc.item())\n",
    "    \n",
    "    # Calculer le F1-score pour la classe minoritaire (label 1)\n",
    "    val_f1_class1 = f1_score(val_true, val_pred, pos_label=1, zero_division=0)\n",
    "    history['val_f1_minority'].append(val_f1_class1)\n",
    "\n",
    "    print(f'  Val. loss: {val_loss:.4f} | Val. Accuracy: {val_acc:.4f} | Val. F1 (Classe 1): {val_f1_class1:.4f}')\n",
    "\n",
    "    # Condition de sauvegarde basée sur le F1-score de la classe minoritaire\n",
    "    if val_f1_class1 > best_val_f1_minority:\n",
    "        best_val_f1_minority = val_f1_class1\n",
    "        print(f\"  Nouveau meilleur modèle (F1 Classe 1) sauvegardé avec Val F1: {best_val_f1_minority:.4f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "95a0ea61",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (4,) and (1,)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[62]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Plot 1: Loss (Training vs. Validation)\u001b[39;00m\n\u001b[32m      8\u001b[39m plt.subplot(\u001b[32m1\u001b[39m, \u001b[32m3\u001b[39m, \u001b[32m1\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[43mplt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs_range\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtrain_loss\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mo-\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mTrain Loss\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m plt.plot(epochs_range, history[\u001b[33m'\u001b[39m\u001b[33mval_loss\u001b[39m\u001b[33m'\u001b[39m], \u001b[33m'\u001b[39m\u001b[33mo-\u001b[39m\u001b[33m'\u001b[39m, label=\u001b[33m'\u001b[39m\u001b[33mValidation Loss\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     11\u001b[39m plt.xlabel(\u001b[33m'\u001b[39m\u001b[33mEpochs\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Simoh\\Github\\BERT_Response_Validity_Checker\\.venv\\Lib\\site-packages\\matplotlib\\pyplot.py:3838\u001b[39m, in \u001b[36mplot\u001b[39m\u001b[34m(scalex, scaley, data, *args, **kwargs)\u001b[39m\n\u001b[32m   3830\u001b[39m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes.plot)\n\u001b[32m   3831\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mplot\u001b[39m(\n\u001b[32m   3832\u001b[39m     *args: \u001b[38;5;28mfloat\u001b[39m | ArrayLike | \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   3836\u001b[39m     **kwargs,\n\u001b[32m   3837\u001b[39m ) -> \u001b[38;5;28mlist\u001b[39m[Line2D]:\n\u001b[32m-> \u001b[39m\u001b[32m3838\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgca\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3839\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3840\u001b[39m \u001b[43m        \u001b[49m\u001b[43mscalex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mscalex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3841\u001b[39m \u001b[43m        \u001b[49m\u001b[43mscaley\u001b[49m\u001b[43m=\u001b[49m\u001b[43mscaley\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3842\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m}\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3843\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3844\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Simoh\\Github\\BERT_Response_Validity_Checker\\.venv\\Lib\\site-packages\\matplotlib\\axes\\_axes.py:1777\u001b[39m, in \u001b[36mAxes.plot\u001b[39m\u001b[34m(self, scalex, scaley, data, *args, **kwargs)\u001b[39m\n\u001b[32m   1534\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1535\u001b[39m \u001b[33;03mPlot y versus x as lines and/or markers.\u001b[39;00m\n\u001b[32m   1536\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   1774\u001b[39m \u001b[33;03m(``'green'``) or hex strings (``'#008000'``).\u001b[39;00m\n\u001b[32m   1775\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1776\u001b[39m kwargs = cbook.normalize_kwargs(kwargs, mlines.Line2D)\n\u001b[32m-> \u001b[39m\u001b[32m1777\u001b[39m lines = [*\u001b[38;5;28mself\u001b[39m._get_lines(\u001b[38;5;28mself\u001b[39m, *args, data=data, **kwargs)]\n\u001b[32m   1778\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines:\n\u001b[32m   1779\u001b[39m     \u001b[38;5;28mself\u001b[39m.add_line(line)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Simoh\\Github\\BERT_Response_Validity_Checker\\.venv\\Lib\\site-packages\\matplotlib\\axes\\_base.py:297\u001b[39m, in \u001b[36m_process_plot_var_args.__call__\u001b[39m\u001b[34m(self, axes, data, return_kwargs, *args, **kwargs)\u001b[39m\n\u001b[32m    295\u001b[39m     this += args[\u001b[32m0\u001b[39m],\n\u001b[32m    296\u001b[39m     args = args[\u001b[32m1\u001b[39m:]\n\u001b[32m--> \u001b[39m\u001b[32m297\u001b[39m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_plot_args\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    298\u001b[39m \u001b[43m    \u001b[49m\u001b[43maxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[43m=\u001b[49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    299\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_kwargs\u001b[49m\n\u001b[32m    300\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Simoh\\Github\\BERT_Response_Validity_Checker\\.venv\\Lib\\site-packages\\matplotlib\\axes\\_base.py:494\u001b[39m, in \u001b[36m_process_plot_var_args._plot_args\u001b[39m\u001b[34m(self, axes, tup, kwargs, return_kwargs, ambiguous_fmt_datakey)\u001b[39m\n\u001b[32m    491\u001b[39m     axes.yaxis.update_units(y)\n\u001b[32m    493\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m x.shape[\u001b[32m0\u001b[39m] != y.shape[\u001b[32m0\u001b[39m]:\n\u001b[32m--> \u001b[39m\u001b[32m494\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mx and y must have same first dimension, but \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    495\u001b[39m                      \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mhave shapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    496\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m x.ndim > \u001b[32m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m y.ndim > \u001b[32m2\u001b[39m:\n\u001b[32m    497\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mx and y can be no greater than 2D, but have \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    498\u001b[39m                      \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mshapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mValueError\u001b[39m: x and y must have same first dimension, but have shapes (4,) and (1,)"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- 6. Visualisation des Courbes ---\n",
    "if EPOCHS > 0: # Plot seulement si l'entraînement a eu lieu\n",
    "    epochs_range = range(1, EPOCHS + 1)\n",
    "\n",
    "    plt.figure(figsize=(18, 5))\n",
    "\n",
    "    # Plot 1: Loss (Training vs. Validation)\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.plot(epochs_range, history['train_loss'], 'o-', label='Train Loss')\n",
    "    plt.plot(epochs_range, history['val_loss'], 'o-', label='Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training & Validation Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Plot 2: Accuracy (Training vs. Validation)\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.plot(epochs_range, history['train_acc'], 'o-', label='Train Accuracy')\n",
    "    plt.plot(epochs_range, history['val_acc'], 'o-', label='Validation Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Training & Validation Accuracy')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Plot 3: Validation F1-score (Minority Class)\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.plot(epochs_range, history['val_f1_minority'], 'o-', label='Validation F1 (Classe 1)', color='green')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('F1 Score (Classe 1)')\n",
    "    plt.title('Validation F1 Score (Minority Class)')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.tight_layout() # Ajuste automatiquement les subplots pour qu'ils ne se chevauchent pas\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"EPOCHS = 0, pas de courbes à afficher.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "757ca840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Évaluation finale du modèle sur l'ensemble de test...\n",
      "Test Loss: 0.3042 | Test Accuracy: 0.8984\n",
      "Métriques pour la Classe 1 (Cohérent):\n",
      "  Precision: 0.6299\n",
      "  Recall:    0.9417\n",
      "  F1-score:  0.7549\n",
      "Métriques pour la Classe 0 (Non Cohérent):\n",
      "  Precision: 0.9871\n",
      "  Recall:    0.8897\n",
      "  F1-score:  0.9359\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# --- 6. Évaluation Finale et Métriques détaillée ---\n",
    "\n",
    "print(\"\\nÉvaluation finale du modèle sur l'ensemble de test...\")\n",
    "final_test_acc, final_test_loss, true_labels, pred_labels = eval_model_fn(\n",
    "    model, test_loader, device, len(test_dataset)\n",
    ")\n",
    "print(f'Test Loss: {final_test_loss:.4f} | Test Accuracy: {final_test_acc:.4f}')\n",
    "\n",
    "\n",
    "# Spécifiez pos_label=1 pour être sûr que c'est pour la classe positive\n",
    "precision_class1 = precision_score(true_labels, pred_labels, pos_label=1, zero_division=0)\n",
    "recall_class1 = recall_score(true_labels, pred_labels, pos_label=1, zero_division=0)\n",
    "f1_class1 = f1_score(true_labels, pred_labels, pos_label=1, zero_division=0)\n",
    "print(f'Métriques pour la Classe 1 (Cohérent):')\n",
    "print(f'  Precision: {precision_class1:.4f}')\n",
    "print(f'  Recall:    {recall_class1:.4f}')\n",
    "print(f'  F1-score:  {f1_class1:.4f}')\n",
    "\n",
    "precision_class0 = precision_score(true_labels, pred_labels, pos_label=0, zero_division=0)\n",
    "recall_class0 = recall_score(true_labels, pred_labels, pos_label=0, zero_division=0)\n",
    "f1_class0 = f1_score(true_labels, pred_labels, pos_label=0, zero_division=0)\n",
    "print(f'Métriques pour la Classe 0 (Non Cohérent):')\n",
    "print(f'  Precision: {precision_class0:.4f}')\n",
    "print(f'  Recall:    {recall_class0:.4f}')\n",
    "print(f'  F1-score:  {f1_class0:.4f}')\n",
    "\n",
    "\n",
    "cm = confusion_matrix(true_labels, pred_labels)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Non Cohérent (0)', 'Cohérent (1)'], yticklabels=['Non Cohérent (0)', 'Cohérent (1)'])\n",
    "plt.xlabel('Prédictions')\n",
    "plt.ylabel('Vraies Étiquettes')\n",
    "plt.title('Matrice de Confusion')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132d2fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Décoder les input_ids pour récupérer le texte\n",
    "decoded_texts = [tokenizer.decode(item['input_ids'], skip_special_tokens=True) for item in test_dataset]\n",
    "\n",
    "df_results = pd.DataFrame({\n",
    "    'decoded_input': decoded_texts,\n",
    "    'true_label': true_labels,\n",
    "    'pred_label': pred_labels\n",
    "})\n",
    "\n",
    "# Afficher toutes les lignes (None signifie illimité)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "# Afficher toutes les colonnes si tu veux aussi\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Afficher toute la largeur d’une colonne (pour éviter les \"...\")\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "false_positives = df_results[(df_results['true_label'] == 0) & (df_results['pred_label'] == 1)]\n",
    "false_negatives = df_results[(df_results['true_label'] == 1) & (df_results['pred_label'] == 0)]\n",
    "\n",
    "print(\"==== FAUX POSITIFS ====\") #Faux le model prédit Cohérent\n",
    "print(false_positives[['decoded_input']].head())\n",
    "\n",
    "print(\"\\n==== FAUX NÉGATIFS ====\")\n",
    "print(false_negatives[['decoded_input']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "35acf423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modèle final (state_dict) sauvegardé sous: vr_save_model_fr/camembert_coherence_final_model.bin\n",
      "Tokenizer sauvegardé sous: vr_save_model_fr/camembert_coherence_tokenizer/\n",
      "\n",
      "Sauvegarde terminée.\n"
     ]
    }
   ],
   "source": [
    "# CELLULE POUR SAUVEGARDER LE MODÈLE ET LE TOKENIZER\n",
    "\n",
    "# --- 7. Sauvegarder le modèle final entraîné ---\n",
    "MODEL_SAVE_PATH = \"vr_save_model_fr/camembert_coherence_final_model.bin\"\n",
    "TOKENIZER_SAVE_PATH = \"vr_save_model_fr/camembert_coherence_tokenizer/\" # Un répertoire\n",
    "\n",
    "# S'assurer que le modèle est sur CPU avant de sauvegarder pour une meilleure portabilité\n",
    "# (Surtout si vous comptez le charger sur une machine sans GPU)\n",
    "model.to('cpu')\n",
    "torch.save(model.state_dict(), MODEL_SAVE_PATH)\n",
    "print(f\"Modèle final (state_dict) sauvegardé sous: {MODEL_SAVE_PATH}\")\n",
    "\n",
    "# Remettre le modèle sur son device original si besoin de continuer à l'utiliser dans cette session\n",
    "model.to(device)\n",
    "\n",
    "# Sauvegarder le tokenizer (contient vocabulaire, configuration, etc.)\n",
    "tokenizer.save_pretrained(TOKENIZER_SAVE_PATH)\n",
    "print(f\"Tokenizer sauvegardé sous: {TOKENIZER_SAVE_PATH}\")\n",
    "\n",
    "print(\"\\nSauvegarde terminée.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "63b76474",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Simoh\\Github\\BERT_Response_Validity_Checker\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of CamembertForSequenceClassification were not initialized from the model checkpoint at camembert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modèle et tokenizer chargés depuis le disque et prêts pour l'inférence.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import re \n",
    "\n",
    "\n",
    "MODEL_NAME_FOR_TEST = \"camembert-base\"\n",
    "MAX_LEN_FOR_TEST = 160 \n",
    "MODEL_SAVE_PATH_FOR_LOAD = \"vr_save_model_fr/camembert_coherence_final_model.bin\"\n",
    "TOKENIZER_SAVE_PATH_FOR_LOAD = \"vr_save_model_fr/camembert_coherence_tokenizer/\"\n",
    "DEVICE_FOR_TEST = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "def clean_text_for_prediction(text):\n",
    "    text = str(text)\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s\\.\\?,!àâéèêëîïôûùüçÀÂÉÈÊËÎÏÔÛÙÜÇ\\']', '', text)\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "\n",
    "model_to_test = None\n",
    "tokenizer_to_test = None\n",
    "device_to_test = None\n",
    "max_len_to_test = None\n",
    "clean_text_func_to_use = None\n",
    "\n",
    "\n",
    "tokenizer_to_test = AutoTokenizer.from_pretrained(TOKENIZER_SAVE_PATH_FOR_LOAD)\n",
    "\n",
    "\n",
    "model_to_test = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME_FOR_TEST, num_labels=2)\n",
    "\n",
    "# Charger les poids sauvegardés\n",
    "model_to_test.load_state_dict(torch.load(MODEL_SAVE_PATH_FOR_LOAD, map_location=DEVICE_FOR_TEST))\n",
    "model_to_test.to(DEVICE_FOR_TEST)\n",
    "model_to_test.eval() \n",
    "\n",
    "max_len_to_test = MAX_LEN_FOR_TEST \n",
    "clean_text_func_to_use = clean_text_for_prediction\n",
    "device_to_test = DEVICE_FOR_TEST \n",
    "\n",
    "print(\"Modèle et tokenizer chargés depuis le disque et prêts pour l'inférence.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ebe59a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Fonction de prédiction (utilise les variables _to_test) ---\n",
    "def predict_coherence(question, answer, model, tokenizer, device, max_len, clean_fn):\n",
    "\n",
    "    cleaned_question = clean_fn(question)\n",
    "    cleaned_answer = clean_fn(answer)\n",
    "\n",
    "    encoding = tokenizer.encode_plus(\n",
    "        cleaned_question,\n",
    "        cleaned_answer,\n",
    "        add_special_tokens=True,\n",
    "        max_length=max_len,\n",
    "        return_token_type_ids=False,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_attention_mask=True,\n",
    "        return_tensors='pt',\n",
    "    )\n",
    "\n",
    "    input_ids = encoding['input_ids'].to(device)\n",
    "    attention_mask = encoding['attention_mask'].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        probs = torch.softmax(logits, dim=1)\n",
    "        prediction_idx = torch.argmax(probs, dim=1).cpu().item()\n",
    "        probability_score = probs[0][prediction_idx].cpu().item()\n",
    "\n",
    "    return prediction_idx, probability_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a6a8d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Exemple 1:\n",
      "  Question: \"Bonjour, que puis-je faire pour vous aujourd'hui ?\"\n",
      "  Réponse:  \"je voudrais des chaussures.\"\n",
      "  Prédiction: Cohérent (Label: 1, Confiance: 0.9347)\n",
      "\n",
      "Exemple 2:\n",
      "  Question: \"Bonjour, que puis-je faire pour vous aujourd'hui ?\"\n",
      "  Réponse:  \"je voudrais des bananes.\"\n",
      "  Prédiction: Cohérent (Label: 1, Confiance: 0.7456)\n",
      "\n",
      "Exemple 3:\n",
      "  Question: \"Quelle est votre taille habituelle ?\"\n",
      "  Réponse:  \"42.\"\n",
      "  Prédiction: Cohérent (Label: 1, Confiance: 0.9398)\n",
      "\n",
      "Exemple 4:\n",
      "  Question: \"Quelle est votre taille habituelle ?\"\n",
      "  Réponse:  \"la hauteur d'un panier de basket est de 3m05.\"\n",
      "  Prédiction: Non Cohérent (Label: 0, Confiance: 0.9348)\n",
      "\n",
      "Exemple 5:\n",
      "  Question: \"Avez-vous une couleur ou un style en tête ?\"\n",
      "  Réponse:  \"oui un style normal de couleur bleue.\"\n",
      "  Prédiction: Cohérent (Label: 1, Confiance: 0.9409)\n",
      "\n",
      "Exemple 6:\n",
      "  Question: \"Avez-vous une couleur ou un style en tête ?\"\n",
      "  Réponse:  \"le vert est la couleur du kiwi.\"\n",
      "  Prédiction: Non Cohérent (Label: 0, Confiance: 0.7328)\n",
      "\n",
      "Exemple 7:\n",
      "  Question: \"Ce modèle vous plaît-il ?\"\n",
      "  Réponse:  \"oui, il est parfait.\"\n",
      "  Prédiction: Cohérent (Label: 1, Confiance: 0.9397)\n",
      "\n",
      "Exemple 8:\n",
      "  Question: \"Ce modèle vous plaît-il ?\"\n",
      "  Réponse:  \"je prend l'avion demain.\"\n",
      "  Prédiction: Non Cohérent (Label: 0, Confiance: 0.9375)\n",
      "\n",
      "Exemple 9:\n",
      "  Question: \"Souhaitez-vous essayer autre chose ou passer en caisse ?\"\n",
      "  Réponse:  \"je veux payer maintenant.\"\n",
      "  Prédiction: Cohérent (Label: 1, Confiance: 0.9392)\n",
      "\n",
      "Exemple 10:\n",
      "  Question: \"Souhaitez-vous essayer autre chose ou passer en caisse ?\"\n",
      "  Réponse:  \"payer avec une pomme c'est possible ?.\"\n",
      "  Prédiction: Non Cohérent (Label: 0, Confiance: 0.8858)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- Exemples de test ---\n",
    "test_samples = [\n",
    "    {\n",
    "        \"question\": \"Bonjour, que puis-je faire pour vous aujourd'hui ?\",\n",
    "        \"answer\": \"je voudrais des chaussures.\"\n",
    "    }, # Cohérent\n",
    "    {\n",
    "        \"question\": \"Bonjour, que puis-je faire pour vous aujourd'hui ?\",\n",
    "        \"answer\": \"je voudrais des bananes.\"\n",
    "    }, # Incohérent\n",
    "    {\n",
    "        \"question\": \"Quelle est votre taille habituelle ?\",\n",
    "        \"answer\": \"42.\"\n",
    "    }, # Cohérent\n",
    "    {\n",
    "        \"question\": \"Quelle est votre taille habituelle ?\",\n",
    "        \"answer\": \"la hauteur d'un panier de basket est de 3m05.\"\n",
    "    }, # Incohérent\n",
    "    {\n",
    "        \"question\": \"Avez-vous une couleur ou un style en tête ?\",\n",
    "        \"answer\": \"oui un style normal de couleur bleue.\"\n",
    "    }, # Cohérent\n",
    "    {\n",
    "        \"question\": \"Avez-vous une couleur ou un style en tête ?\",\n",
    "        \"answer\": \"le vert est la couleur du kiwi.\"\n",
    "    }, # Incohérent\n",
    "    {\n",
    "        \"question\": \"Ce modèle vous plaît-il ?\",\n",
    "        \"answer\": \"oui, il est parfait.\"\n",
    "    }, # Cohérent\n",
    "    {\n",
    "        \"question\": \"Ce modèle vous plaît-il ?\",\n",
    "        \"answer\": \"je prend l'avion demain.\"\n",
    "    }, # Incohérent\n",
    "    {\n",
    "        \"question\": \"Souhaitez-vous essayer autre chose ou passer en caisse ?\",\n",
    "        \"answer\": \"je veux payer maintenant.\"\n",
    "    }, # Cohérent\n",
    "    {\n",
    "        \"question\": \"Souhaitez-vous essayer autre chose ou passer en caisse ?\",\n",
    "        \"answer\": \"payer avec une pomme c'est possible ?.\"\n",
    "    },# Incohérent\n",
    "]\n",
    "\n",
    "\n",
    "for i, sample in enumerate(test_samples):\n",
    "    q = sample[\"question\"]\n",
    "    a = sample[\"answer\"]\n",
    "\n",
    "    print(f\"\\nExemple {i+1}:\")\n",
    "    print(f\"  Question: \\\"{q}\\\"\")\n",
    "    print(f\"  Réponse:  \\\"{a}\\\"\")\n",
    "\n",
    "    pred_label, pred_prob = predict_coherence(q, a,\n",
    "                                                model_to_test,\n",
    "                                                tokenizer_to_test,\n",
    "                                                device_to_test,\n",
    "                                                max_len_to_test,\n",
    "                                                clean_text_func_to_use)\n",
    "\n",
    "\n",
    "    coherence_status = \"Cohérent\" if pred_label == 1 else \"Non Cohérent\"\n",
    "    print(f\"  Prédiction: {coherence_status} (Label: {pred_label}, Confiance: {pred_prob:.4f})\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
